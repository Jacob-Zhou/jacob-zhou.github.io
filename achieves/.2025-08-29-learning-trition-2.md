---
layout:     post
title:      "Triton 学习手记 （三）：利用 Triton 自定义 PyTorch 操作"
description: "利用 Triton 自定义 PyTorch 操作"
date:       2025-08-29 19:00:0+0800
author:     "Houquan Zhou"
header-img: "/assets/img/post-bg.jpg"
mathjax: true
catalog: true
hidden: true
tags:
    - Triton
    - 手记
---

## 前言

在[之前的手记](/2025/08/19/learning-trition-0)中，我们介绍了 Triton 的基本概念，介绍了 Triton 的编程模型，以及如何利用 Triton 来读写 Tensor。


<!-- 在这篇手记中，我们将介绍如何让 Triton 与 PyTorch 结合 -->

## 使用 Triton 自定义 PyTorch 操作

```python
@triton.jit
def kernel_fwd(
    x_ptr,
    N: tl.constexpr,
    M: tl.constexpr
):
    pass

@triton.jit
def kernel_bwd(
    x_ptr,
    N: tl.constexpr,
    M: tl.constexpr
):
    pass

def helper_fwd(x: torch.Tensor):
    pass

def helper_bwd(dy: torch.Tensor):
    pass

class Function(torch.autograd.Function):

    @staticmethod
    @input_guard  # 用于确保输入的 Tensor 是连续的
    def forward(ctx, input: torch.Tensor):
        return helper_fwd(input)

    @staticmethod
    @input_guard
    def backward(ctx, dy: torch.Tensor):
        dx = helper_bwd(dy)
        return dx, None, None

def fn(input: torch.Tensor):
    return Function.apply(input)
```

## Flash Attention 2 的 Triton 实现
